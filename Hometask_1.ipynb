{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\ttais\\appdata\\roaming\\python\\python310\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\ttais\\appdata\\roaming\\python\\python310\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\ttais\\appdata\\roaming\\python\\python310\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\ttais\\appdata\\roaming\\python\\python310\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrdL__lCtr6M"
   },
   "source": [
    "## Базовые требования к домашкам\n",
    "\n",
    "1. Формат - jupyter-тетрадка или скрипт на питоне\n",
    "2. Мы запускаем ваши тетрадки с нуля, поэтому следите, чтобы не было \n",
    "- необъявленных переменных (удалили ячейку, а переменная продолжает использоваться)\n",
    "- лишних принтов отладочной информации (пожалуйста! это очень мешает проверяющему, когда приходится пролистать 10 страниц текста без кода)\n",
    "3. Комментарии приветствуются!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание: Оценка тональности по словарю\n",
    "В рамках этого задания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является отзыв положительным или отрицательным. \n",
    "Делать мы будем это таким образом: мы возьмём некоторое число отзывов, заранее размеченных как положительные или отрицательные; выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах, и будем считать, каких слов  в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "Мы будем работать по заранее определённому пайплайну:\n",
    "\n",
    "1. Сначала нам надо скачать данные -- соберите как минимум 60 (30 положительных  и 30 отрицательных) отзывов на похожие продукты (не надо мешать отзывы на отели с отзывами на ноутбуки) для составления \"тонального словаря\" (чем больше отзывов, тем лучше) и 10 отзывов для проверки качества. (2 балла в случае сбора путём парсинга, 1 - если найдете уже готовые данные или просто закопипастите без парсинга)\n",
    "Примечание: сбор данных с помощью краулинга может занять много времени, советуем сначала реализовать всё задание на готовых данных, а затем сделать с краулингом, если хотите получить 9 или 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьму отзывы на драмы с сайта kinopoisk.ru. Всего 80 положительных, 80 отрицательных и 20 валидационных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант с краулингом сайта, который иногда не работает из-за блокировок со стороны сайта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_url = 'https://www.kinopoisk.ru/reviews/type/comment/status/good/genre/8/period/month/perpage/100/#list'\n",
    "bad_url = 'https://www.kinopoisk.ru/reviews/type/comment/status/bad/genre/8/period/month/perpage/100/#list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = UserAgent().chrome\n",
    "good_response = requests.get(good_url, headers={'User-Agent': user_agent})\n",
    "good_response.encoding = 'utf-8'\n",
    "good_page = good_response.text\n",
    "good_soup = BeautifulSoup(good_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = UserAgent().chrome\n",
    "bad_response = requests.get(bad_url, headers={'User-Agent': user_agent})\n",
    "bad_response.encoding = 'utf-8'\n",
    "bad_page = bad_response.text\n",
    "bad_soup = BeautifulSoup(bad_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант с парсингом скачанной html-страницы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good_url = https://www.kinopoisk.ru/reviews/type/comment/status/good/genre/8/period/month/perpage/100/#list\n",
    "\n",
    "bad_url = https://www.kinopoisk.ru/reviews/type/comment/status/bad/genre/8/period/month/perpage/100/#list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('good_page_100.html', encoding='utf-8') as good_page:\n",
    "    good_soup = BeautifulSoup(good_page, 'html.parser')\n",
    "with open('bad_page_100.html', encoding='utf-8') as bad_page:\n",
    "    bad_soup = BeautifulSoup(bad_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews = good_soup.find_all('span', {'itemprop': 'reviewBody'})\n",
    "bad_reviews = bad_soup.find_all('span', {'itemprop': 'reviewBody'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(reviews):\n",
    "    review_texts = []\n",
    "    for review in reviews:\n",
    "        review_texts.append(review.text)\n",
    "    return review_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_review_texts = extract_text(good_reviews)\n",
    "bad_review_texts = extract_text(bad_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = pd.DataFrame(good_review_texts)\n",
    "good_df['label'] = 1\n",
    "good_df = good_df.rename(columns={0: 'review'})\n",
    "good_validate = good_df.tail(20)\n",
    "good_df = good_df.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = pd.DataFrame(bad_review_texts)\n",
    "bad_df['label'] = 0\n",
    "bad_df = bad_df.rename(columns={0: 'review'})\n",
    "bad_validate = bad_df.tail(20)\n",
    "bad_df = bad_df.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Трудно назвать этот сериал «выдающимся», так к...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Испанский стыд это единственное словосочетание...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Создателями сериала являются Баран бо Одар (ре...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Это мой первый фильм про стрельбу в школе. «Бу...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Данный фильм относится к категории, которая в ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  label\n",
       "112  Трудно назвать этот сериал «выдающимся», так к...      0\n",
       "99   Испанский стыд это единственное словосочетание...      0\n",
       "22   Создателями сериала являются Баран бо Одар (ре...      1\n",
       "150  Это мой первый фильм про стрельбу в школе. «Бу...      0\n",
       "95   Данный фильм относится к категории, которая в ...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([good_df, bad_df], ignore_index=True)\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Фильм Тарковского — один из ярчайших примеров ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Фильм слепленный на коленке. Попытка отрефлекс...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Что за дрянь я посмотрел. Нудятина в обертке д...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>В фильме затронута крайне важная тема, но к со...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Предупреждаем, что ту самую книгу Агаты Кристи...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  label\n",
       "18  Фильм Тарковского — один из ярчайших примеров ...      0\n",
       "12  Фильм слепленный на коленке. Попытка отрефлекс...      0\n",
       "13  Что за дрянь я посмотрел. Нудятина в обертке д...      0\n",
       "11  В фильме затронута крайне важная тема, но к со...      0\n",
       "15  Предупреждаем, что ту самую книгу Агаты Кристи...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate = pd.concat([good_validate, bad_validate])\n",
    "y = validate.sample(20, ignore_index=True)\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_CzjN-StydR"
   },
   "source": [
    "2. Токенизируйте слова, приведите их к нижнему регистру и к начальной форме  (1 балл за токенизацию, 1 - за начальную форму)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "\n",
    "def lemmatize(review):\n",
    "    tokens = ''\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for token in tokenizer.tokenize(review):\n",
    "        token = morph.normal_forms(token)[0]\n",
    "        tokens = tokens + ' ' + token\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemmatized = X.copy()\n",
    "for i in range(len(X)):\n",
    "    X_lemmatized.loc[i, 'review'] = lemmatize(X.loc[i, 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>художественный фильм по мотив известный реаль...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>у я просто язык не повернуться назвать это ка...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>любовь всё преодолевать это очень противный о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сериал клан сопрано the sopranos считаться од...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>в 2006 год один из самый хороший и многообеща...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0   художественный фильм по мотив известный реаль...      1\n",
       "1   у я просто язык не повернуться назвать это ка...      1\n",
       "2   любовь всё преодолевать это очень противный о...      1\n",
       "3   сериал клан сопрано the sopranos считаться од...      1\n",
       "4   в 2006 год один из самый хороший и многообеща...      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lemmatized = y.copy()\n",
    "for i in range(len(y)):\n",
    "    y_lemmatized.loc[i, 'review'] = lemmatize(y.loc[i, 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вступление выход крид наследие рокк в 2015 м ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>воскликнуть в искренний порыв ипполит в ирони...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>наверняка быть тот кто пойти на этот фильм в ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>через два год после прочтение отличный книга ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>первый сезон зацепить особо неожиданный сюжет...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0   вступление выход крид наследие рокк в 2015 м ...      0\n",
       "1   воскликнуть в искренний порыв ипполит в ирони...      0\n",
       "2   наверняка быть тот кто пойти на этот фильм в ...      0\n",
       "3   через два год после прочтение отличный книга ...      1\n",
       "4   первый сезон зацепить особо неожиданный сюжет...      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_lemmatized = X_lemmatized[X_lemmatized['label'] == 1]\n",
    "good_lemmatized.reset_index(inplace=True)\n",
    "bad_lemmatized = X_lemmatized[X_lemmatized['label'] == 0]\n",
    "bad_lemmatized.reset_index(inplace=True)\n",
    "\n",
    "good_words_list = []\n",
    "bad_words_list = []\n",
    "for i in range(len(good_lemmatized)):\n",
    "    good_words_list.extend(good_lemmatized.loc[i, 'review'].split())\n",
    "    bad_words_list.extend(bad_lemmatized.loc[i, 'review'].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Составьте 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных. Попробуйте поиграть с частотностями и исключить шум (к примеру, выбросить слова, встречающиеся 1-2 раза) (2 балла) (если у вас получились пустые множества, уберите фильтр по частотности или увеличьте выборку)\n",
    "В случае, если после долгих мучений в п. 3 множества по объективным причинам не получается (покажите, что пытались) - отправляйте жабу - зачтём полный балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cnt = Counter(good_words_list)\n",
    "for key, value in good_cnt.copy().items():\n",
    "    if value <= 3:\n",
    "        del good_cnt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cnt = Counter(bad_words_list)\n",
    "for key, value in bad_cnt.copy().items():\n",
    "    if value <= 2:\n",
    "        del bad_cnt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_good = set(good_cnt) - set(bad_cnt)\n",
    "len(only_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_bad = set(bad_cnt) - set(good_cnt)\n",
    "len(only_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1  - за коректно работающую функцию, 1 - за подсчёт accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_review_tonality(review):\n",
    "    review_lemmas = review.split()\n",
    "    good_score = 0\n",
    "    bad_score = 0\n",
    "    for lemma in review_lemmas:\n",
    "        if lemma in only_good:\n",
    "            good_score += 1\n",
    "        elif lemma in only_bad:\n",
    "            bad_score += 1\n",
    "    if good_score > bad_score:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_lemmatized)):\n",
    "    review = y_lemmatized.loc[i, 'review']\n",
    "    y_pred = determine_review_tonality(review)\n",
    "    y_true = y_lemmatized.loc[i, 'label']\n",
    "    if y_pred == y_true:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy / len(y_lemmatized)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Предложите как минимум 2 способа улучшить этот алгоритм определения тональности отзыва (1 балл за описание и реализацию каждого способа; если 2 способа описаны только текстом, это 1 балл. За третий и последующие способы дополнительных баллов не будет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант 1.** Можно работать не с множествами уникальных для отзывов данной тональности слов, а со словарями частотности слов в положительных и в отрицательных отзывах и давать балл в пользу той тональности, в которой это слово встречается чаще (на всякий случай - значительно чаще, по крайней мере на 5 раз чаще)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_review_tonality_better1(review):\n",
    "    review_lemmas = review.split()\n",
    "    good_score = 0\n",
    "    bad_score = 0\n",
    "    for lemma in review_lemmas:\n",
    "        if lemma in good_cnt and lemma not in bad_cnt:\n",
    "            good_score += 1\n",
    "        elif lemma in bad_cnt and lemma not in good_cnt:\n",
    "            bad_score += 1\n",
    "        elif lemma in good_cnt and lemma in bad_cnt:\n",
    "            if good_cnt[lemma] >= bad_cnt[lemma] + 5:\n",
    "                good_score += 1\n",
    "            elif bad_cnt[lemma] >= good_cnt[lemma] + 5:\n",
    "                bad_score += 1\n",
    "    if good_score > bad_score:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_lemmatized)):\n",
    "    review = y_lemmatized.loc[i, 'review']\n",
    "    y_pred = determine_review_tonality_better1(review)\n",
    "    y_true = y_lemmatized.loc[i, 'label']\n",
    "    if y_pred == y_true:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy / len(y_lemmatized)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, метод оказался весьма так себе - качество он скорее портит, чем улучшает. Видимо, это связано с тем, что в моих словарях положительных и отрицательных слов, даже несмотря на удаление слишком низкочастотных, очень много случайных слов и оттого работа просто с частотностями тоже оказывается во многом случайно раздающей баллы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант 2.** Можно попробовать поработать со стоп-словами, исключив их из списков слов для тональностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 540)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_good), len(only_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(only_words):\n",
    "    only_words\n",
    "    for only_word in only_words.copy():\n",
    "        if only_word in russian_stopwords:\n",
    "            only_words.remove(only_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords(only_good)\n",
    "remove_stopwords(only_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 538)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_good), len(only_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_lemmatized)):\n",
    "    review = y_lemmatized.loc[i, 'review']\n",
    "    y_pred = determine_review_tonality(review)\n",
    "    y_true = y_lemmatized.loc[i, 'label']\n",
    "    if y_pred == y_true:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy / len(y_lemmatized)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, стоп-слов оказалось не настолько много и они оказались не настолько значимыми, чтобы повлиять на качество определения тональности. Либо же качество тоже ухудшается скорее в меньшую сторону, видимо, оттого, что всё-таки при определении тональности нередко значимыми оказываются как раз высокочастотные слова (хотя это не всегда так и в задачах определения тональности, насколько я знаю, стоп-слова иногда действительно удаляются, и это улучшает качество)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhO9ANVm4SXK9q5vI0e+E4",
   "collapsed_sections": [],
   "name": "Hometask 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
